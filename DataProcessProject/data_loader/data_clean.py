import argparse
import os
import numpy as np


def remove_invalid_flares(lc_data, label_data, mask_data, min_rise=0.001):
    """
    åˆ é™¤ label=1 ä¸” max_rise <= min_rise çš„æ ·æœ¬ï¼ˆå½»åº•ç§»é™¤ï¼‰

    Returns:
        cleaned_lc: np.ndarray, shape [N_clean, 1, 512]
        cleaned_labels: np.ndarray, shape [N_clean,]
        removed_indices: list of indices that were removed
    """
    keep_mask = np.ones(len(label_data), dtype=bool)
    removed_indices = []
    valid_rises = []

    for i in range(len(label_data)):
        if label_data[i] == 1:
            lc = lc_data[i, 0, :]  # shape [512]
            diff = lc[1:] - lc[:-1]
            max_rise = np.max(diff)

            if max_rise <= min_rise:
                keep_mask[i] = False
                removed_indices.append(i)
            else:
                valid_rises.append(max_rise)

    cleaned_lc = lc_data[keep_mask]
    cleaned_labels = label_data[keep_mask]
    cleaned_mask = mask_data[keep_mask]

    print(f"åŽŸå§‹æ ·æœ¬æ•°: {len(label_data)}")
    print(f"åŽŸå§‹è€€æ–‘æ•°: {np.sum(label_data == 1)}")
    print(f"åˆ é™¤æ ·æœ¬æ•°: {len(removed_indices)} (å…¨éƒ¨ä¸º label=1 ä¸” max_rise <= {min_rise})")
    print(f"æ¸…æ´—åŽæ ·æœ¬æ•°: {len(cleaned_labels)}")
    print(f"æ¸…æ´—åŽè€€æ–‘æ•°: {np.sum(cleaned_labels == 1)}")
    print(f"æ¸…æ´—åŽå¯¹åº”çš„åŽ†å²è€€æ–‘è®°å½•æ•°: {len(cleaned_mask)}")


    # è®¡ç®— q5ï¼ˆä»…ç”¨äºŽ train é›†ï¼‰
    if valid_rises:
        q5 = np.percentile(valid_rises, 5)
        recommended = q5 * 0.8
        print(f"q5: {q5:.6f} â†’ æŽ¨è rise_threshold: {recommended:.6f}")
    else:
        recommended = 0.005

    return cleaned_lc, cleaned_labels,cleaned_mask, recommended


def main():
    parser = argparse.ArgumentParser(description="Process dataset with robust patching and splitting.")
    parser.add_argument(
        "--dataset",
        type=str,
        choices=["kepler", "tess"],
        required=True,
        help="Dataset identifier: 'kepler' or 'tess'"
    )

    args = parser.parse_args()
    if args.dataset == "kepler":
        output_root = "../myDataK"  # æ–°ç›®å½•åï¼Œé¿å…æ··æ·†
    elif args.dataset == "tess":
        output_root = "../myDataH"  # æ–°ç›®å½•åï¼Œé¿å…æ··æ·†
    else:
        raise ValueError("Unsupported dataset. Choose 'kepler' or 'tess'.")

    data_root = "../no_leak_dataset"
    splits = ["train", "val", "test"]
    min_rise = 0.001

    os.makedirs(output_root, exist_ok=True)
    global_threshold = None

    for split in splits:
        print(f"\n{'=' * 50}")
        print(f"ðŸ§¹ ä¸¥æ ¼æ¸…æ´— {split} é›†ï¼ˆåˆ é™¤æ— æ•ˆæ ·æœ¬ï¼‰")
        print(f"{'=' * 50}")

        lc_path = os.path.join(data_root, split, "lc_data.npy")
        label_path = os.path.join(data_root, split, "label_data.npy")
        mask_path = os.path.join(data_root, split, "mask_data.npy")

        lc_data = np.load(lc_path)
        label_data = np.load(label_path)
        mask_data = np.load(mask_path)

        print(f"åŠ è½½: {lc_data.shape}, {label_data.shape}, {mask_data.shape}")

        cleaned_lc, cleaned_labels, cleaned_mask, rec_thresh = remove_invalid_flares(
            lc_data, label_data,mask_data, min_rise=min_rise
        )

        if split == "train":
            global_threshold = rec_thresh

        # ä¿å­˜æ¸…æ´—åŽçš„æ•°æ®
        out_dir = os.path.join(output_root, split)
        os.makedirs(out_dir, exist_ok=True)

        np.save(os.path.join(out_dir, "lc_data.npy"), cleaned_lc)
        np.save(os.path.join(out_dir, "label_data.npy"), cleaned_labels)
        np.save(os.path.join(out_dir, "mask_data.npy"), cleaned_mask)


        print(f"âœ… å·²ä¿å­˜è‡³: {out_dir}")
        print("After clean, our data shape is ")
        print(f"lc_data.shape: {cleaned_lc.shape}")
        print(f"label_data.shape: {cleaned_labels.shape}")
        print(f"mask_data.shape: {cleaned_mask.shape}")


    print(f"\n{'=' * 60}")
    print(f"ðŸŽ¯ æœ€ç»ˆæŽ¨è rise_thresholdï¼ˆåŸºäºŽæ¸…æ´—åŽçš„ train é›†ï¼‰: {global_threshold:.6f}")
    print(f"ä½¿ç”¨å»ºè®®: PhysicsRegularizedLoss(rise_threshold={global_threshold:.6f})")
    print(f"{'=' * 60}")


if __name__ == "__main__":
    main()