import torch.nn.functional as F
import argparse
from einops import rearrange

from pytorch_lightning import LightningModule, Trainer
from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from pytorch_lightning.strategies import DDPStrategy

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, average_precision_score, \
    roc_auc_score, fbeta_score

from transformers import GPT2Model


import os
import numpy as np

import math
import torch
import torch.nn as nn


class PhysicsRegularizedLoss(nn.Module):
    def __init__(self, lambda_phys=0.1, conf_threshold = 0.5, use_data="kepler"): # todo, è¿™é‡Œçš„rise_thresholdå€¼ï¼Œæœ‰ä¸¤ä¸ªé€‰æ‹©ï¼Œ
        super().__init__()
        rise_threshold = [0.0175, 0.0132] # åˆ†åˆ«æ˜¯[kepler: 0.0175 å’Œ tessï¼š 0.0132]

        self.ce_loss = nn.CrossEntropyLoss()
        self.lambda_phys = lambda_phys
        self.conf_threshold = conf_threshold  # â† æ–°å¢å‚æ•°, å¯è°ƒçš„ç½®ä¿¡åº¦é˜ˆå€¼, é»˜è®¤å¹³è¡¡ç‚¹ï¼Œä¸ºäº†ç¨³å®šç‰©ç†æ­£åˆ™åŒ–çº¦æŸ

        if use_data == "kepler":
            self.rise_threshold = rise_threshold[0]
            # TODO lambda_phys=0.1
        elif use_data == "tess":
            self.rise_threshold = rise_threshold[1]
            # TODO lambda_phys=0.1

        print("å®éªŒæ‰€ç”¨æ•°æ®é›†ä¸º: ", use_data)
        print("å®éªŒæ‰€ç”¨è¶…å‚æ•°lambda_physä¸º: ", self.lambda_phys)
        print("å®éªŒæ‰€ç”¨è¶…å‚æ•°rise_thresholdä¸º: ", self.rise_threshold)

    def forward(self, logits, targets, input_lc):
        # åŸå§‹åˆ†ç±»æŸå¤±
        ce = self.ce_loss(logits, targets)

        # ç‰©ç†çº¦æŸæŸå¤±ï¼šä»…å¯¹çœŸå®è€€æ–‘ï¼ˆlabel=1ï¼‰çš„æ ·æœ¬è¿›è¡Œè®¡ç®—
        flare_mask = (targets == 1).float() # [B] è¿”å›å€¼æ˜¯ä¸€ä¸ªå¸ƒå°”æ•°ç»„å—ï¼Ÿ
        if flare_mask.sum() == 0:
            phys_loss = torch.tensor(0.0, device=logits.device)
        else:
            phys_loss = self.flare_shape_penalty_on_true_flare(input_lc, flare_mask)

        return ce + self.lambda_phys * phys_loss

    def flare_shape_penalty_on_true_flare(self, input_lc, flare_mask):
        diff = input_lc[:, 1:] - input_lc[:, :-1]  # [B, L-1]

        max_rise = torch.max(diff, dim=1).values  # [B]# å¯¹çœŸå®è€€æ–‘ï¼šè‹¥ max_rise < thresholdï¼Œ åˆ™æƒ©ç½š
        penalty = torch.relu(self.rise_threshold - max_rise)  # [B]#åªå¯¹çœŸå®è€€æ–‘æ ·æœ¬è®¡ç®—æŸå¤±
        weighted_penalty = penalty * flare_mask

        return weighted_penalty.sum() / (flare_mask.sum() + 1e-8)


    def flare_shape_penalty(self, input_lc, pred_probs):
        """
        lc: [B, L] åŸå§‹å…‰å˜æ›²çº¿
        pred_prob: [B] æ¨¡å‹é¢„æµ‹ä¸ºè€€æ–‘çš„æ¦‚ç‡
        è¿”å›ï¼šè¿åè€€æ–‘å½¢çŠ¶å…ˆéªŒçš„æƒ©ç½š
        """
        # è®¡ç®—ä¸€é˜¶å¯¼æ•°ï¼ˆè¿‘ä¼¼ä¸Šå‡/ä¸‹é™é€Ÿç‡ï¼‰
        diff = input_lc[:, 1:] - input_lc[:, :-1]  # [B, L-1]

        # è€€æ–‘åº”æœ‰æ˜¾è‘—ä¸Šå‡æ®µ
        max_rise = torch.max(diff, dim=1).values  # [B]

        # è‹¥é¢„æµ‹æ˜¯è€€æ–‘ä½†æ— æ˜¾è‘—ä¸Šå‡ï¼Œåˆ™æƒ©ç½š
        penalty = torch.relu(self.rise_threshold - max_rise)

        # åŠ æƒ: åªæƒ©ç½šé«˜ç½®ä¿¡åº¦é¢„æµ‹ï¼ˆpred_prob > 0.5ï¼‰# pred_prob å‚æ•°å¯è°ƒ TODO
        weight = torch.clamp(pred_probs - self.conf_threshold, min=0.0)

        return ((penalty * weight).mean() * weight).mean()

class TokenEmbedding(nn.Module):
    def __init__(self, c_in, d_model):
        super(TokenEmbedding, self).__init__()
        padding = 1 if torch.__version__ >= '1.5.0' else 2
        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,
                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)
        for m in self.modules():
            if isinstance(m, nn.Conv1d):
                nn.init.kaiming_normal_(
                    m.weight, mode='fan_in', nonlinearity='leaky_relu')

    def forward(self, x):
        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)
        return x


class PositionalEmbedding(nn.Module):
    def __init__(self, d_model, max_len=5000):
        super(PositionalEmbedding, self).__init__()
        # Compute the positional encodings once in log space.
        pe = torch.zeros(max_len, d_model).float()
        pe.require_grad = False

        position = torch.arange(0, max_len).float().unsqueeze(1)
        div_term = (torch.arange(0, d_model, 2).float()
                    * -(math.log(10000.0) / d_model)).exp()

        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)

        pe = pe.unsqueeze(0)
        self.register_buffer('pe', pe)

    def forward(self, x):
        return self.pe[:, :x.size(1)]


class FixedEmbedding(nn.Module):
    def __init__(self, c_in, d_model):
        super(FixedEmbedding, self).__init__()

        w = torch.zeros(c_in, d_model).float()
        w.require_grad = False

        position = torch.arange(0, c_in).float().unsqueeze(1)
        div_term = (torch.arange(0, d_model, 2).float()
                    * -(math.log(10000.0) / d_model)).exp()

        w[:, 0::2] = torch.sin(position * div_term)
        w[:, 1::2] = torch.cos(position * div_term)

        self.emb = nn.Embedding(c_in, d_model)
        self.emb.weight = nn.Parameter(w, requires_grad=False)

    def forward(self, x):
        return self.emb(x).detach()


class TemporalEmbedding(nn.Module):
    def __init__(self, d_model, embed_type='fixed', freq='h'):
        super(TemporalEmbedding, self).__init__()

        minute_size = 4
        hour_size = 24
        weekday_size = 7
        day_size = 32
        month_size = 13

        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding
        if freq == 't':
            self.minute_embed = Embed(minute_size, d_model)
        self.hour_embed = Embed(hour_size, d_model)
        self.weekday_embed = Embed(weekday_size, d_model)
        self.day_embed = Embed(day_size, d_model)
        self.month_embed = Embed(month_size, d_model)

    def forward(self, x):
        x = x.long()
        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(
            self, 'minute_embed') else 0.
        hour_x = self.hour_embed(x[:, :, 3])
        weekday_x = self.weekday_embed(x[:, :, 2])
        day_x = self.day_embed(x[:, :, 1])
        month_x = self.month_embed(x[:, :, 0])

        return hour_x + weekday_x + day_x + month_x + minute_x


class TimeFeatureEmbedding(nn.Module):
    def __init__(self, d_model, embed_type='timeF', freq='h'):
        super(TimeFeatureEmbedding, self).__init__()

        freq_map = {'h': 4, 't': 5, 's': 6,
                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}
        d_inp = freq_map[freq]
        self.embed = nn.Linear(d_inp, d_model, bias=False)

    def forward(self, x):
        return self.embed(x)


class DataEmbedding(nn.Module):
    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):
        super(DataEmbedding, self).__init__()

        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)
        self.position_embedding = PositionalEmbedding(d_model=d_model)
        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,
                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(
            d_model=d_model, embed_type=embed_type, freq=freq)
        self.dropout = nn.Dropout(p=dropout)

    def forward(self, x, x_mark):
        if x_mark is None:
            x = self.value_embedding(x) + self.position_embedding(x)
        else:
            x = self.value_embedding(
                x) + self.temporal_embedding(x_mark) + self.position_embedding(x)
        return self.dropout(x)


# ---------------------
# 1. å®šä¹‰æœ¬åœ°æ¨¡å‹è·¯å¾„ # æ³¨. è¿™ä¸ªéœ€è¦æœ¬åœ°æ¨¡å‹gpt2
# ---------------------
LOCAL_MODEL_PATH = "models/gpt2/"


class gpt4ts(nn.Module):
    def __init__(self, input_dim):
        super(gpt4ts, self).__init__()
        self.pred_len = 0
        self.seq_len = 512
        self.max_len = 512
        self.patch_size = 16
        self.stride = 2
        self.gpt_layers = 6
        self.feat_dim = input_dim  # todo
        self.num_classes = 2
        self.d_model = 768

        self.patch_num = (self.seq_len - self.patch_size) // self.stride + 1

        self.padding_patch_layer = nn.ReplicationPad1d((0, self.stride))
        self.patch_num += 1
        self.enc_embedding = DataEmbedding(self.feat_dim * self.patch_size, 768, 0.1)

        self.gpt2 = GPT2Model.from_pretrained(LOCAL_MODEL_PATH,
                                              output_attentions=True, output_hidden_states=True, local_files_only=True)
        self.gpt2.h = self.gpt2.h[:self.gpt_layers]

        for i, (name, param) in enumerate(self.gpt2.named_parameters()):
            if 'ln' in name or 'wpe' in name:
                param.requires_grad = True
            else:
                param.requires_grad = False

        device = torch.device('cuda:{}'.format(0))

        self.act = F.gelu
        self.dropout = nn.Dropout(0.1)
        self.ln_proj = nn.LayerNorm(768 * self.patch_num)

        self.ln_proj = nn.LayerNorm(768 * self.patch_num)
        self.out_layer = nn.Linear(768 * self.patch_num, self.num_classes)

    def forward(self, x_enc):
        # B, L, M = x_enc.shape
        #
        # input_x = rearrange(x_enc, 'b l m -> b m l')


        input = x_enc.permute(0,2,1).contiguous()
        B, M, L = input.shape


        input_x = self.padding_patch_layer(input)  # todo
        input_x = input_x.unfold(dimension=-1, size=self.patch_size, step=self.stride).contiguous()
        input_x = rearrange(input_x, 'b m n p -> b n (p m)')

        outputs = self.enc_embedding(input_x, None)
        outputs = outputs.contiguous()

        outputs = self.gpt2(inputs_embeds=outputs).last_hidden_state

        outputs = outputs.contiguous()  # â†â†â† æ–°å¢ï¼ç¡®ä¿ GPT2 è¾“å‡ºè¿ç»­
        outputs = self.act(outputs).reshape(B, -1)
        outputs = self.ln_proj(outputs)
        outputs = self.out_layer(outputs)

        return outputs


# ---------------------
# 4. è‡ªå®šä¹‰æ¨¡å‹
# ---------------------
class CustomModel(nn.Module):
    def __init__(self, input_dim=1):
        super().__init__()
        self.gpt4ts = gpt4ts(input_dim)

    def forward(self, x_enc=None, **kwargs):
        logits = self.gpt4ts(x_enc)
        return logits


# ---------------------
# 5. LightningModuleå°è£…
# ---------------------
class Gpt4tsLightningModule(LightningModule):
    def __init__(self, num_classes=2, input_dim=4, lr=1e-4, on_phy_loss=True, text_emb_dim=768, use_multimodal=True, model_type="gpt4ts", use_data="kepler"): # todo input_dim éœ€è¦ä¿®æ”¹ï¼š1 Or 4
        super().__init__()
        self.save_hyperparameters()
        self.model_type = model_type

        # åˆå§‹åŒ–æ¨¡å‹
        self.model = CustomModel(input_dim)

        # å¼•å…¥ç‰©ç†æŸå¤±å‡½æ•°
        self.on_phy_loss = on_phy_loss
        self.criterion = nn.CrossEntropyLoss()
        if self.on_phy_loss:
            self.criterion = PhysicsRegularizedLoss(use_data=use_data)

        # è·å–æ˜¯å¦å¼€å¯å¤šæ¨¡æ€
        self.use_multimodal = use_multimodal

        # === Multimodal Fusion: Text Embedding Compressor ===
        self.text_proj = nn.Linear(text_emb_dim, 512)  # out_features : ç‰¹å¾ç»´åº¦
        self.text_act = nn.ReLU()  # optional non-linearity

        # å¦‚æœå½“å‰ä¸ä½¿ç”¨å¤šæ¨¡æ€ï¼Œå†»ç»“è¿™äº›å±‚ï¼
        if not self.use_multimodal:  # å‡è®¾ä½ æœ‰ä¸€ä¸ªæ ‡å¿—ä½ï¼Œæ¯”å¦‚ args.multimodal æˆ– self.hparams.multimodal
            for param in self.text_proj.parameters():
                param.requires_grad = False

        self.validation_outputs = []
        self.test_outputs = []

    def forward(self, enc, text_emb=None, his_emb=None):
        if text_emb is not None:
            # Compress text: [B, text_dim] -> [B, L]
            text_comp = self.text_act(self.text_proj(text_emb))  # [B, k], k <=4
            enc = torch.cat([enc, text_comp.unsqueeze(-1)], dim=-1)  # [B, L, C + C]
        if his_emb is not None: # æ·»åŠ æ–‡æœ¬ï¼ˆå†å²åºåˆ—ï¼‰åµŒå…¥
            his_comp = self.text_act(self.text_proj(his_emb))
            enc = torch.cat([enc, his_comp.unsqueeze(-1)], dim=-1)
        return self.model(enc)

    @classmethod
    def load_from_saved_model(cls, path, **kwargs):
        """ä»ä¿å­˜çš„æ¨¡å‹åŠ è½½"""
        # åŠ è½½é…ç½®
        config_path = os.path.join(path, "config.bin")
        if os.path.exists(config_path):
            config = torch.load(config_path)
            # åˆå¹¶ç”¨æˆ·æä¾›çš„å‚æ•°å’Œä¿å­˜çš„é…ç½®
            for key, value in config.items():
                if key not in kwargs:
                    kwargs[key] = value

        # åˆ›å»ºæ¨¡å‹å®ä¾‹
        model = cls(**kwargs)

        # åŠ è½½æ¨¡å‹æƒé‡
        model_path = os.path.join(path, "pytorch_model.bin")
        if os.path.exists(model_path):
            state_dict = torch.load(model_path)
            # å¤„ç†å¯èƒ½çš„æ¨¡å—å‰ç¼€
            model_to_load = model.model.module if hasattr(model.model, 'module') else model.model
            model_to_load.load_state_dict(state_dict)

        # åŠ è½½LightningModuleçŠ¶æ€
        lightning_module_path = os.path.join(path, "lightning_module.bin")
        if os.path.exists(lightning_module_path):
            checkpoint = torch.load(lightning_module_path)
            # åªåŠ è½½éœ€è¦çš„çŠ¶æ€ï¼Œé¿å…è¦†ç›–å·²åŠ è½½çš„æ¨¡å‹æƒé‡
            model.load_state_dict(checkpoint['state_dict'], strict=False)

        return model

    def training_step(self, batch, batch_idx):
        x_enc, text_emb, his_emb, y, raw_lc = self._prepare_batch(batch)
        # æµ‹è¯• ï¼š x_enc's shape = (16, 512, 1)
        logits = self(x_enc, text_emb, his_emb)  # âœ… æ­£ç¡®è°ƒç”¨

        # å¼•å…¥ç‰©ç†æŸå¤±åï¼š âœ… æ­£ç¡®è®¡ç®— lossï¼šåœ¨ device ä¸Šè®¡ç®—ï¼Œlabel éœ€ squeeze ä¸”ä¸º long
        if self.on_phy_loss:
            loss = self.criterion(logits, y, raw_lc)
        else:
            loss = self.criterion(logits, y.squeeze().long())

        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, sync_dist=True)
        return loss

    def _prepare_batch(self, batch):  # ç¼–å†™é¢„è§£åŒ…é€»è¾‘
        inputs, label = batch
        x_enc = inputs['x_enc'].float().to(self.device)
        text_emb = inputs['text_emb'].float().to(self.device) if inputs['text_emb'] is not None else None
        his_emb = inputs['his_emb'].float().to(self.device) if inputs['his_emb'] is not None else None
        raw_lc = inputs['raw_lc'].float().to(self.device)
        return x_enc, text_emb, his_emb, label.to(self.device), raw_lc

    def validation_step(self, batch, batch_idx):
        x_enc, text_emb, his_emb, y, raw_lc = self._prepare_batch(batch)
        # print("x_enc shape:", x_enc.shape)  # åº”è¯¥æ˜¯ [B, C, L]
        logits = self(x_enc, text_emb, his_emb)
        # å¼•å…¥ç‰©ç†æŸå¤±åï¼š âœ… æ­£ç¡®è®¡ç®— lossï¼šåœ¨ device ä¸Šè®¡ç®—ï¼Œlabel éœ€ squeeze ä¸”ä¸º long
        if self.on_phy_loss:
            loss = self.criterion(logits, y, raw_lc)
        else:
            loss = self.criterion(logits, y.squeeze().long())

        preds = torch.argmax(logits, dim=1)
        probs = F.softmax(logits, dim=1)

        # å­˜å‚¨åˆ° CPUï¼ˆé¿å… OOMï¼‰?
        self.validation_outputs.append({
            'loss': loss,
            'preds': preds.cpu().numpy(),
            'probs': probs.cpu().numpy(),
            'y_true': y.cpu().numpy()
        })
        return loss

    def on_validation_epoch_end(self):
        outputs = self.validation_outputs
        all_y_true = np.concatenate([o['y_true'] for o in outputs])
        all_probs = np.concatenate([o['probs'] for o in outputs])  # shape: (N, 2)

        # # åªæœ‰å¯ç”¨åŠ¨æ€é˜ˆå€¼æ—¶æ‰ä¿å­˜éªŒè¯é›†æ¦‚ç‡å’Œæ ‡ç­¾ ã€val_dynamic_thresholdã€‘ç»è¿‡å®éªŒï¼Œæ•ˆæœä¸€èˆ¬ï¼Œæš‚æ—¶ä¸è€ƒè™‘
        # if self.on_val_dynamic_threshold:
        #     # ä¿å­˜éªŒè¯é›†æ­£ç±»æ¦‚ç‡å’ŒçœŸå®æ ‡ç­¾ï¼ˆç”¨äºåç»­æ‰¾é˜ˆå€¼ï¼‰
        #     self.val_probs = all_probs[:, 1]  # æ­£ç±»æ¦‚ç‡
        #     self.val_trues = all_y_true.flatten()

        # åŸæœ‰æŒ‡æ ‡è®¡ç®—ï¼ˆä»ç”¨é»˜è®¤é˜ˆå€¼=0.5ï¼Œç”¨äºæ—©åœç›‘æ§ï¼‰
        self._compute_and_log_metrics(self.validation_outputs, prefix="val")
        self.validation_outputs.clear()

    def test_step(self, batch, batch_idx):
        x_enc, text_emb, his_emb, y, raw_lc = self._prepare_batch(batch)
        logits = self(x_enc, text_emb, his_emb)
        # å¼•å…¥ç‰©ç†æŸå¤±åï¼š âœ… æ­£ç¡®è®¡ç®— lossï¼šåœ¨ device ä¸Šè®¡ç®—ï¼Œlabel éœ€ squeeze ä¸”ä¸º long
        if self.on_phy_loss:
            loss = self.criterion(logits, y, raw_lc)
        else:
            loss = self.criterion(logits, y.squeeze().long())

        preds = torch.argmax(logits, dim=1)
        probs = F.softmax(logits, dim=1)

        self.test_outputs.append({
            'loss': loss,
            'preds': preds.cpu().numpy(),
            'probs': probs.cpu().numpy(),
            'y_true': y.cpu().numpy()
        })
        return loss

    def _compute_and_log_metrics_with_custom_preds(self, y_true, y_pred, probs, loss, prefix="test", threshold=0.5,
                                                   val_f2=None):
        # åŠ æƒæŒ‡æ ‡
        acc_w = accuracy_score(y_true, y_pred)
        f1_w = f1_score(y_true, y_pred, average='weighted')
        rec_w = recall_score(y_true, y_pred, average='weighted')
        prec_w = precision_score(y_true, y_pred, average='weighted')

        # æ­£ç±»æŒ‡æ ‡
        rec_pos = recall_score(y_true, y_pred, pos_label=1, average='binary')
        prec_pos = precision_score(y_true, y_pred, pos_label=1, average='binary')
        f1_pos = f1_score(y_true, y_pred, pos_label=1, average='binary')
        f2_pos = fbeta_score(y_true, y_pred, beta=2.0, pos_label=1, average='binary')

        # AUCï¼ˆä¸å˜ï¼Œå› ä¸ºç”¨çš„æ˜¯åŸå§‹æ¦‚ç‡ï¼‰
        auc_roc = auc_pr = float('nan')
        if len(np.unique(y_true)) == 2:
            auc_roc = roc_auc_score(y_true, probs[:, 1])
            auc_pr = average_precision_score(y_true, probs[:, 1])

        # æ—¥å¿—
        self.log(f'{prefix}_loss', loss, sync_dist=True)
        self.log(f'{prefix}_accuracy', acc_w, sync_dist=True)
        self.log(f'{prefix}_f1_weighted', f1_w, sync_dist=True)
        self.log(f'{prefix}_recall_pos', rec_pos, sync_dist=True)
        self.log(f'{prefix}_precision_pos', prec_pos, sync_dist=True)
        self.log(f'{prefix}_f1_pos', f1_pos, sync_dist=True)
        self.log(f'{prefix}_f2_pos', f2_pos, sync_dist=True)
        self.log(f'{prefix}_threshold_used', threshold, sync_dist=True)

        if auc_roc != float('nan'):
            self.log(f'{prefix}_auc_roc', auc_roc, sync_dist=True)
            self.log(f'{prefix}_auc_pr', auc_pr, sync_dist=True)

        # æ‰“å°ç»“æœ
        print("\n" + "=" * 60)
        print(f"ã€{prefix.upper()} é›†æœ€ç»ˆç»“æœï¼ˆåŠ¨æ€é˜ˆå€¼ï¼‰ã€‘")
        print("=" * 60)
        print(f"Threshold used: {threshold:.3f}")
        if val_f2 is not None:
            print(f"F2 on val (for threshold selection): {val_f2:.4f}")
        print(f"Loss: {loss:.6f}")
        print("\nã€åŠ æƒæŒ‡æ ‡ï¼ˆæ•´ä½“ï¼‰ã€‘")
        print(f"Accuracy: {acc_w:.6f}")
        print(f"F1 (weighted): {f1_w:.6f}")
        print(f"Recall (weighted): {rec_w:.6f}")
        print(f"Precision (weighted): {prec_w:.6f}")
        print("\nã€æ­£ç±»æŒ‡æ ‡ï¼ˆlabel=1ï¼‰ã€‘ â† æ ¸å¿ƒï¼")
        print(f"Recall (TPR): {rec_pos:.6f}")
        print(f"Precision: {prec_pos:.6f}")
        print(f"F1-score: {f1_pos:.6f}")
        print(f"F2-score: {f2_pos:.6f}")
        print(f"AUC-ROC: {auc_roc:.6f}")
        print(f"AUC-PR: {auc_pr:.6f}")
        print("=" * 60)

        result_text = (
            f"Accuracy: {acc_w:.6f}\n"
            f"Recall (TPR): {rec_pos:.6f}\n"
            f"Precision: {prec_pos:.6f}\n"
            f"F1-score: {f1_pos:.6f}\n"
            f"AUC-ROC: {auc_roc:.6f}\n"
        )

        # å¯é€‰ï¼šä¿å­˜åˆ°æ–‡ä»¶ï¼ˆæ¨¡ä»¿ä½ çš„ç‰ˆæœ¬1ï¼‰
        folder_path = f'./results/testResult_{self.model_type}/'
        os.makedirs(folder_path, exist_ok=True)
        with open(os.path.join(folder_path, 'result_classification.txt'), 'a') as f:
            f.write("-" * 50 + "\n\n")
            f.write(result_text)
            f.write("-" * 50 + "\n\n")

    def on_test_epoch_end(self):
        outputs = self.test_outputs
        all_y_true = np.concatenate([o['y_true'] for o in outputs])
        all_probs = np.concatenate([o['probs'] for o in outputs])
        test_probs_positive = all_probs[:, 1]
        avg_loss = np.mean([o['loss'].item() for o in outputs])

        # é»˜è®¤è¡Œä¸ºï¼šä½¿ç”¨ argmaxï¼ˆå³é˜ˆå€¼=0.5ï¼‰
        # if not self.on_val_dynamic_threshold:
        print("ğŸ“Œ Dynamic threshold disabled. Using default threshold (0.5).")
        test_preds = np.argmax(all_probs, axis=1)
        threshold_used = 0.5
        val_f2_for_th = None
        # else: ã€val_dynamic_thresholdã€‘ç»è¿‡å®éªŒï¼Œæ•ˆæœä¸€èˆ¬ï¼Œæš‚æ—¶ä¸è€ƒè™‘
        #     # å¯ç”¨åŠ¨æ€é˜ˆå€¼ï¼šåœ¨éªŒè¯é›†ä¸Šæœç´¢æœ€ä¼˜ F2 é˜ˆå€¼
        #     if self.val_probs is None or self.val_trues is None:
        #         print("âš ï¸ Warning: Validation data not available. Falling back to threshold=0.5.")
        #         test_preds = (test_probs_positive >= 0.5).astype(int)
        #         threshold_used = 0.5
        #         val_f2_for_th = None
        #     else:
        #         print("ğŸ” Searching optimal threshold on validation set for F2...")
        #         best_f2 = -1
        #         best_th = 0.5
        #         for th in np.arange(0.01, 0.9, 0.01):
        #             pred_val = (self.val_probs >= th).astype(int)
        #             f2 = fbeta_score(
        #                 self.val_trues, pred_val,
        #                 beta=2.0, pos_label=1, average='binary', zero_division=0
        #             )
        #             if f2 > best_f2:
        #                 best_f2 = f2
        #                 best_th = th
        #         threshold_used = best_th
        #         val_f2_for_th = best_f2
        #         test_preds = (test_probs_positive >= best_th).astype(int)
        #         print(f"âœ… Best threshold: {best_th:.3f} (F2={best_f2:.4f} on val)")

        # åŸå…ˆçš„æ³¨é‡Šæ‰ï¼š
        # self._compute_and_log_metrics(self.test_outputs, prefix="test", print_results=True)
        # self.test_outputs.clear()
        # ä½¿ç”¨æœ€ç»ˆé¢„æµ‹ç»“æœè®¡ç®—æŒ‡æ ‡
        self._compute_and_log_metrics_with_custom_preds(
            y_true=all_y_true,
            y_pred=test_preds,
            probs=all_probs,
            loss=avg_loss,
            prefix="test",
            threshold=threshold_used,
            val_f2=val_f2_for_th
        )
        self.test_outputs.clear()

    def _compute_and_log_metrics(self, outputs, prefix="val", print_results=False):
        all_preds = np.concatenate([o['preds'] for o in outputs])
        all_y_true = np.concatenate([o['y_true'] for o in outputs])
        all_probs = np.concatenate([o['probs'] for o in outputs])
        avg_loss = np.mean([o['loss'].item() for o in outputs])

        # åŠ æƒæŒ‡æ ‡
        acc_w = accuracy_score(all_y_true, all_preds)
        f1_w = f1_score(all_y_true, all_preds, average='weighted')
        rec_w = recall_score(all_y_true, all_preds, average='weighted')
        prec_w = precision_score(all_y_true, all_preds, average='weighted')

        # æ­£ç±»æŒ‡æ ‡ï¼ˆlabel=1ï¼‰
        try:
            rec_pos = recall_score(all_y_true, all_preds, pos_label=1, average='binary')
            prec_pos = precision_score(all_y_true, all_preds, pos_label=1, average='binary')
            f1_pos = f1_score(all_y_true, all_preds, pos_label=1, average='binary')
            f2_pos = fbeta_score(all_y_true, all_preds, beta=2.0, pos_label=1, average='binary')
        except ValueError:
            rec_pos = prec_pos = f1_pos = f2_pos = float('nan')

        # AUC
        auc_roc = auc_pr = float('nan')
        if len(np.unique(all_y_true)) == 2:
            auc_roc = roc_auc_score(all_y_true, all_probs[:, 1])
            auc_pr = average_precision_score(all_y_true, all_probs[:, 1])

        # æ—¥å¿—
        self.log(f'{prefix}_loss', avg_loss, sync_dist=True)
        self.log(f'{prefix}_accuracy', acc_w, sync_dist=True)
        self.log(f'{prefix}_f1_weighted', f1_w, sync_dist=True)
        self.log(f'{prefix}_recall_pos', rec_pos, sync_dist=True)
        self.log(f'{prefix}_precision_pos', prec_pos, sync_dist=True)
        self.log(f'{prefix}_f1_pos', f1_pos, sync_dist=True)

        self.log(f'{prefix}_f2_pos', f2_pos, sync_dist=True)

        if auc_roc != float('nan'):
            self.log(f'{prefix}_auc_roc', auc_roc, sync_dist=True)
            self.log(f'{prefix}_auc_pr', auc_pr, sync_dist=True)

        if print_results:
            print("\n" + "=" * 60)
            print(f"ã€{prefix.upper()} é›†æœ€ç»ˆç»“æœã€‘")
            print("=" * 60)
            print(f"Loss: {avg_loss:.6f}")
            print("\nã€åŠ æƒæŒ‡æ ‡ï¼ˆæ•´ä½“ï¼‰ã€‘")
            print(f"Accuracy: {acc_w:.6f}")
            print(f"F1 (weighted): {f1_w:.6f}")
            print(f"Recall (weighted): {rec_w:.6f}")
            print(f"Precision (weighted): {prec_w:.6f}")
            print("\nã€æ­£ç±»æŒ‡æ ‡ï¼ˆlabel=1ï¼‰ã€‘ â† æ ¸å¿ƒï¼")
            print(f"Recall (TPR): {rec_pos:.6f}")
            print(f"Precision: {prec_pos:.6f}")
            print(f"F1-score: {f1_pos:.6f}")
            print(f"F2-score: {f2_pos:.6f}")
            print(f"AUC-ROC: {auc_roc:.6f}")
            print(f"AUC-PR: {auc_pr:.6f}")
            print("=" * 60)

    def configure_optimizers(self):
        return torch.optim.AdamW(self.model.parameters(), lr=self.hparams.lr)

    def save_model(self, path):
        """ä¿å­˜æ¨¡å‹ï¼Œå…¼å®¹PyTorch Lightningçš„æ£€æŸ¥ç‚¹æ ¼å¼"""
        os.makedirs(path, exist_ok=True)

        # ä¿å­˜æ¨¡å‹æƒé‡
        model_to_save = self.model.module if hasattr(self.model, 'module') else self.model
        torch.save(model_to_save.state_dict(), os.path.join(path, "pytorch_model.bin"))

        # ä¿å­˜é…ç½®ä¿¡æ¯
        config = {
            'num_classes': self.hparams.num_classes,
            'input_dim': self.hparams.input_dim,
            'lr': self.hparams.lr,
            # æ·»åŠ å…¶ä»–éœ€è¦çš„é…ç½®å‚æ•°
        }
        torch.save(config, os.path.join(path, "config.bin"))

        # ä¿å­˜å®Œæ•´çš„LightningModuleçŠ¶æ€
        torch.save({
            'state_dict': self.state_dict(),
            'hparams': self.hparams,
            # å¯ä»¥æ·»åŠ å…¶ä»–éœ€è¦ä¿å­˜çš„çŠ¶æ€
        }, os.path.join(path, "lightning_module.bin"))

        print(f"Model saved to {path}")


# ---------------------
# 6. ä¸»å‡½æ•°ï¼ˆæ·»åŠ æ—©åœï¼‰
# ---------------------
def main(args):
    # åˆå§‹åŒ–LightningModule
    model = Gpt4tsLightningModule(
        num_classes=args.num_classes,
        input_dim=args.input_dim,
        lr=args.lr
    )

    # é…ç½®æ£€æŸ¥ç‚¹å›è°ƒ
    checkpoint_callback = ModelCheckpoint(
        monitor='val_f1',
        dirpath=args.output_dir,
        filename='gpt4ts-best-model',
        save_top_k=1,
        mode='max'
    )

    # é…ç½®æ—©åœå›è°ƒï¼ˆè€å¿ƒå€¼10è½®ï¼‰
    early_stopping = EarlyStopping(
        monitor='val_f1',  # ç›‘è§†éªŒè¯å‡†ç¡®ç‡
        patience=10,  # æ—©åœè½®æ•°
        mode='max',  # æœ€å¤§åŒ–å‡†ç¡®ç‡
        verbose=True,
        check_finite=True
    )

    # é…ç½®TensorBoardæ—¥å¿—
    logger = TensorBoardLogger(save_dir='logs', name='lora-gpt4ts')

    # åˆå§‹åŒ–Trainerï¼Œæ·»åŠ æ—©åœå›è°ƒ
    trainer = Trainer(
        max_epochs=args.epochs,
        accelerator='gpu',
        devices="auto",
        callbacks=[checkpoint_callback, early_stopping],
        logger=logger,
        log_every_n_steps=50,
        enable_progress_bar=True,
        strategy=DDPStrategy(find_unused_parameters=True)
    )



# if __name__ == "__main__":
#     parser = argparse.ArgumentParser(description='LoRA fine-tuning with gpt2 using PyTorch Lightning')

#     # æ•°æ®å‚æ•°
#     parser.add_argument('--train_path', type=str, default='./dataset_k/train', help='Path to training data')
#     parser.add_argument('--test_path', type=str, default='./dataset_k/test', help='Path to test data')
#     parser.add_argument('--val_path', type=str, default='./dataset_k/val', help='Path to val data')
#     parser.add_argument('--output_dir', type=str, default='./gpt4ts_saved', help='Output directory for saved model')

#     # æ¨¡å‹å‚æ•°
#     parser.add_argument('--num_classes', type=int, default=2, help='Number of output classes')
#     parser.add_argument('--input_dim', type=int, default=1, help='Input feature dimension')

#     # è®­ç»ƒå‚æ•°
#     parser.add_argument('--batch_size', type=int, default=16, help='Batch size per GPU')
#     parser.add_argument('--lr', type=float, default=1e-4, help='Learning rate')
#     parser.add_argument('--epochs', type=int, default=100, help='Number of training epochs (æ—©åœå¯èƒ½æå‰ç»ˆæ­¢)')  # todo
#     parser.add_argument('--num_workers', type=int, default=0, help='Number of data loading workers')
#     # TODO
#     # å¦‚æœæœ‰ç°æœ‰çš„æ¨¡å‹ï¼Œå¯ä»¥ç›´æ¥æµ‹è¯•ï¼Œåˆ™æ‰“å¼€è¿™ä¸ªå‚æ•°é¡¹
#     parser.add_argument('--all', action='store_true',
#                         help='Enable all innovations')
#     # è‹¥å¼€å¯å¤šæ¨¡æ€ï¼Œåˆ™éœ€è¦äº‹å…ˆè®¡ç®—æ–‡æœ¬ç¼–ç å‘é‡å¹¶å­˜å…¥ç›¸å…³æ–‡ä»¶å¤¹ã€‚ï¼ˆæ‰§è¡Œæœ¬ç›®å½•ä¸‹çš„generate_text_embeddings.pyæ–‡ä»¶ï¼‰
#     parser.add_argument('--encoder', type=str, default="bert", help='type of encoder we use.')
#     parser.add_argument('--text_emb_dim', type=int, default=768, help='type of encoder we use.')  # æŒ‡å®šå…¶ç‰¹å¾ç»´åº¦

#     # æ˜¯å¦å¼€å¯å•æ¨¡æ€ç‰¹å¾å¢å¼º
#     parser.add_argument('--on_enhance', action='store_true', help='Enable flux augmentation(Add å·®åˆ†)')

#     # æ˜¯å¦å¼€å¯ç‰©ç†æŸå¤±å‡½æ•°çº¦æŸ
#     parser.add_argument('--on_phy_loss', action='store_true', help='Enable physical loss')

#     # å®šä¹‰è°ƒç”¨çš„æ¨¡å‹: bertã€gpt2
#     parser.add_argument('--model_type', type=str, default="bert", help='Model type')

#     # æ˜¯å¦å¼€å¯å¤šæ¨¡æ€æ¨¡å¼ï¼š
#     parser.add_argument('--on_multimodal', action='store_true', help='Enable multimodal input (x_enc + text_emb)')

#     args = parser.parse_args()

#     if args.all:
#         args.input_dim = 4
#         args.on_multimodal = True
#         args.on_enhance = True
#         args.on_phy_loss = True

#     # å…³é”®é…ç½®é«˜äº®å±•ç¤º
#     print("\n" + "=" * 60)
#     print("ğŸ”‘ Key Experimental Settings:")
#     print(f"  â¤ Multimodal (text + LC):              {'âœ… ON' if args.on_multimodal else 'âŒ OFF'}")
#     print(f"  â¤ Time Series Enhancement (Î”flux):     {'âœ… ON' if args.on_enhance else 'âŒ OFF'}")
#     print(f"  â¤ Physics-Regularized Loss:            {'âœ… ON' if args.on_phy_loss else 'âŒ OFF'}")
#     print("=" * 60 + "\n")

#     # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
#     os.makedirs(args.output_dir, exist_ok=True)

#     # è¿è¡Œä¸»å‡½æ•°
#     main(args)
